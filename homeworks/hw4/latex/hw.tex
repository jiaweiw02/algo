\documentclass[
	12pt
]{fphw}
\usepackage[utf8]{inputenc} % Required for inputting international characters
\usepackage[T1]{fontenc} % Output font encoding for international characters
\usepackage{mathpazo} % Use the Palatino font
\usepackage{graphicx} % Required for including images
\usepackage{booktabs} % Required for better horizontal rules in tables
\usepackage{listings} % Required for insertion of code
\usepackage{enumerate} % To modify the enumerate environment
\usepackage{amsmath, amssymb} % For math symbols
\usepackage{mathtools} % For floor and ceil
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

%----------------------------------------------------------------------------------------
%	ASSIGNMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Homework 4} % Assignment title

\author{Jiawei Wu} % Student name

\date{Feb 10, 2022} % Due date

\institute{Rensselaer Polytechnic Institute} % Institute or school name

\class{Introduction to Algorithms (CSCI 2300)} % Course or class name

\professor{Dr. Bulent Yener} % Professor or teacher in charge of the assignment

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Output the assignment title, created automatically using the information in the custom commands above

%----------------------------------------------------------------------------------------
%	ASSIGNMENT CONTENT
%----------------------------------------------------------------------------------------

\section*{Question 1}

\begin{problem}
	Computer tight big-Oh bounds for the following recurrences:

	\medskip

	\begin{enumerate}[(\itshape a\normalfont)]
		\item $T(n) = 8T(\frac{n}{4}) + O(n)$
		\item $T(n) = 2T(\frac{n}{4}) + O(\sqrt{n})$
		\item $T(n) = T(n - 4) + O(n^2)$
		\item $T(n) = T(\sqrt{n}) + O(n)$
	\end{enumerate}
\end{problem}
\begin{center}
    For these questions I used the formulas given to us in lecture
	with the following cases: \\
	$T(n) = \Theta(n^d)$ if $d > \log_b a$\\
	$T(n) = \Theta(n^dlogn)$ if $d = \log_b a$\\
	$T(n) = \Theta(n^{\log_b a})$ if $d < \log_b a$
\end{center}

%------------------------------------------------

\subsection*{Answer}
\begin{enumerate}[(\itshape a\normalfont)] % Sub-questions styled as italic letters
	\item $a = 8$, $b = 4$, $d = 1$\\
	Using theorem, we get $\log_b a = \log_4 8$. We can solve the
	algorithm by
	\begin{align*}
		\log_4 8 &= log_{2^2} 2^3 \\
		&= \frac{1}{2} \log_2 2^3 = \frac{3}{2}\\
	\end{align*}
	From the theorem, we know that since $d < \log_b a$, it follows that the tight bound is $\Theta(n^{\log_4 8})$ or $\boxed{\Theta(n^{\frac{3}{2}})}$
	\item $a = 2$, $b = 4$, $d = \frac{1}{2}$ \\
	Solve $\log_b a = \log_4 2$. This solves to $\frac{1}{2}$.\\
	By the theorem, $d = \log_b a$. Therefore, the tight bound is $\boxed{\Theta(n^{\frac{1}{2}}logn)}$
	\item We cannot use the master's theorem for this question, but the recurrence is simple enough that we can analyze it. $T(n-4)$ signifies that the function will run $O(\frac{n}{4})$ times since every time it runs, it decreases by 4.
	Also, $T(n-4)$ will run $O(n^2)$ times, we know this from the $O(n^2)$ in our equations. Our true $O$ notation will be $O(\frac{n}{4} \times n^2)$, which will solve to $O(\frac{n^3}{4})$. Our answer in big O notation will be $\boxed{\mathbf{\Theta(n^3)}}$.
	\item Similarly, we cannot use the master's theorem for this question. The patter that we encounter while trying to solve this problem is represented in the following table:
	\begin{center}
		\begin{tabular}{c | c}
			$R$ & $T$ \\
			1 & $n$ \\
			2 & $n^\frac{1}{2}$ \\
			3 & $n^\frac{1}{4}$ \\
			4 & $n^\frac{1}{8}$ \\
			k & $n^\frac{1}{2^k}$ \\
		\end{tabular}
	\end{center}
	
	From this, we can build the following sigma notation to calculate every value of $T(n)$ up to $n = k$:
	\begin{align*}
		T(n) = \sum_{i=0}^{k} n^{\frac{1}{2^i}}
	\end{align*}
	We can formulate a base case like the following $n^{\frac{1}{2^k}} = 2$, since 2 is the smallest number that is the answer of another number squared. From this, we can continue to solve it:
	\begin{align*}
		\log_2 n^{\frac{1}{2^k}} &= \log_2 2\\
		\frac{1}{2^k} \log_2 n &= \log_2 2\\
		\frac{1}{2^k} &= \frac{\log_2 2}{\log_2 n}\\
		2^k &= \frac{\log_2 n}{\log_2 2}\\
		\log_2 2^k &= \log_2(\frac{\log_2 n}{\log_2 2})\\
		k &= \log_2(\log_2 n)\\
	\end{align*}
	Having solved $k$, we can then plug it into our previous sum:
	\begin{align*}
		T(n) = \sum_{i = 0}^{\log \log(n)} n^{\frac{1}{2^i}}
	\end{align*}
	From this, we can compare it to our previous value:
	\begin{align*}
		\sum_{i = 0}^{\log \log(n)} n^{\frac{1}{2^i}} < \sum_{i = 0}^{\log \log(n)} n
	\end{align*}
	We can define $T(n) = \sum_{i = 0}^{\log \log(n)} n^{\frac{1}{2^i}}$ as smaller than $T(n) = \sum_{i = 0}^{\log \log(n)} n$. So it is our lower bound. Our upper bound will be the bigger value. However, we have to make some key assumption here:
	\begin{center}
		\begin{tabular}{c | c}
			$i$ & value \\
			$0$ & $n$ \\
			$1$ & $\sqrt{n}$ \\
			$2$ & $\sqrt{n}$ \\
			$3$ & $\sqrt{n}$ \\
			$4$ & $\sqrt{n}$ \\
			$k$ & $\sqrt{n}$ \\
		\end{tabular}
	\end{center}
	We assume that every value after $0$ is going to take $\sqrt{n}$ runtime. With this assumption, we can define our upper bound as our tight bound. So, let's solve the equation:
	\begin{align*}
		T(n) &= n + \sum_{i = 1}^{\log_2 \log_2 n} \sqrt{n}\\
		&= n + \log_2 \log_2 n \sqrt{n}
	\end{align*}
	Reaching our true estimate. We will then take the upper bound, and simply assume that every element takes $O(n)$ time to reach the answer of $\boxed{\mathbf{\Theta(\log_2 \log_2 (n) n)}}$. Here we eliminated the constant $n$ in front of the equation, and since we can't establish a bound for $n^{\frac{1}{2^i}}$, we simply assume that it takes $n$ time.
\end{enumerate}

%----------------------------------------------------------------------------------------
\pagebreak
\section*{Question 2}

\begin{problem}
	Let $A$ be an array of $n$ integers, and let $R$ be the range of values in $A$, i.e., $R = \max(A) - \min(A)$. Give an $O(n + R)$ time algorithm to sort all the values in A.
\end{problem}

%------------------------------------------------

\subsection*{Answer}
\begin{verbatim}
	def sortArr(A):
    R = max(A) - min(A)
    count = [0 for i in range(R + 1)]

    for num in A:
        index = num - min(A)
        count[index] += 1
    
    sortedA = []
    for i in range(len(count)):
        value = i + min(A)
        
        for dup in range(count[i]):
            sortedA.append(value)
    
    return sortedA
\end{verbatim}
$\hfill$\\
\indent In this code, I implemented a type of function that utilizes a type of counting hash function. I begin the program by calculating the value of $R$ and initializing an array that holds $R+1$ values. I then loop through every value in A and determine their index based on the difference between their value and the minimum value. A for loop $O(n)$ complexity is then implemented to add the values into the "hash list". Then, I initialize an array called sortedA that holds the return array for the function.\\
\indent My next for loop goes over $O(R)$ values, this is because the length of the count array is $R + 1$. For each value, I then add the $min$ of the array back to the index to get the original value. Since count[i] stores how many times that value appears. Since it is implemented as a hash function, we can assume the inner for loop is indeed $O(1)$ to go over all the duplicates.\\
\indent This implementation is based upon the assumption that we don't have an array such as [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], where in this case, the algorithm wouldn't be very useful in this case because it 

%----------------------------------------------------------------------------------------
\pagebreak
\section*{Question 3}

\begin{problem}
	Let A be an array of n distinct integers. Consider an algorithm to find the minimum value, where we pair up the elements, and retain the smaller of the values from each pair. This will result in an array of half the size (actually the resulting size will be $\ceil*{n/2}$. We can then recursively apply the same approach, until we get a final array with just two elements. We compare these two values and return the minimum of those values as the answer. Answer the following questions:
	
	
	
	
	\medskip
	
	\begin{enumerate}[(\itshape a\normalfont)]
		\item How many comparisons are done in the above algorithm in the worst case.
		\item Show how to modify/extend this method to find the second smallest element.
		\item Prove that we can find the second smallest element in $n + \ceil*{\log n} - 2$ comparisons in the worst case.
	\end{enumerate}

	Note that the above questions are not asking for the big-Oh complexity, but rather the (exact) number of comparisons in the worst case. For example, it is easy to find the 2nd smallest element in at most $2n$ comparisons, but that is $n + n$ which is larger than $n + \ceil*{\log n} - 2$ comparisons.
\end{problem}

%------------------------------------------------

\subsection*{Answer} 

\begin{enumerate}[(\itshape a\normalfont)]
	\item With the following logic: A[i] compares with B[i], for A = Array left, and B = Array right:
	\begin{verbatim}
		initial array:	7 9 8 6 2 1 4 5
		A and B: 7 9 8 6 | 2 1 4 5
		A and B: 2 1 | 4 5
		A and B: 2 | 1
		Answer: 1
	\end{verbatim}
	The number we chose for $n = 8$ is a power of 2. The total number of comparisons done for powers of two will always be $n - 1$, even in the worst case. However, if we have powers that aren't powers of 2, it will be slightly higher, but still proportional to $n$.\\
	$\therefore$ the worst case should be $\boxed{\mathbf{n - 1}}$ comparisons.
	\item We can simply modify this method so that, when it finds the smallest element, it simply removes it from the array. Then, you can run the algorithm again to find the 2nd smallest element.
	\item Note: The answer to this question can also be the answer to B. When comparing the smallest element, there has to be a time that the 2nd smallest element was compared to the smallest element. We also know that since this halfing of array size follows a tree pattern, that means that the smallest element has to have traveled $\log n$ depth in our binary tree in order to become the smallest element. In our answer to A, we mentioned that there are $n-1$ comparisons to find the minimum value. We can here omit the value of comparing in the last step, leading to $n - 2$ comparisons instead. Following this logic, we end up with a total of $n + \ceil{\log n} - 2$ comparisons.
\end{enumerate}

%----------------------------------------------------------------------------------------

\end{document}
